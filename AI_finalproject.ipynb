{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e153219e",
   "metadata": {},
   "source": [
    "# Introduction to AI - Final Project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e1b7b",
   "metadata": {},
   "source": [
    "## Part A. Machine Learning Project (Classification)\n",
    "\n",
    "**Dataset: Processed COVID-19 Data**\n",
    "\n",
    "**Project Overview:**\n",
    "\n",
    "In this project, you should use the COVID-19 data collect by Johns Hopkins University (https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports) for a simple classification task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f9ff70",
   "metadata": {},
   "source": [
    "### Instructions and tasks:\n",
    "\n",
    "**1.\tLoad Data**:\n",
    "\n",
    "Load all the CSV files regarding the Agust 2020, containing COVID-19 data from the provided address and combine them into a unified dataset.\n",
    "\n",
    "08-01-2020.csv\n",
    "\n",
    "08-02-2020.csv\n",
    "\n",
    "08-03-2020.csv\n",
    "\n",
    "...\n",
    "\n",
    "08-28-2020.csv\n",
    "\n",
    "08-29-2020.csv\n",
    "\n",
    "08-30-2020.csv\n",
    "\n",
    "08-31-2020.csv\n",
    "\n",
    "**Hint:** If you want to concatenate the files vertically (stack them on top of each other), you can use the 'concat' function in Python and Pandas.\n",
    "If you don't want to use Python here and prefer a graphical tool, you can use software like Microsoft Excel or Google Sheets to import the CSV files into worksheets and then copy/paste or import the data as needed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3ded4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading files: 100%|██████████| 31/31 [00:18<00:00,  1.68file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm \n",
    "\n",
    "# dates in August 2020\n",
    "dates = [\n",
    "    \"08-01-2020\", \"08-02-2020\", \"08-03-2020\", \"08-04-2020\", \"08-05-2020\",\n",
    "    \"08-06-2020\", \"08-07-2020\", \"08-08-2020\", \"08-09-2020\", \"08-10-2020\",\n",
    "    \"08-11-2020\", \"08-12-2020\", \"08-13-2020\", \"08-14-2020\", \"08-15-2020\",\n",
    "    \"08-16-2020\", \"08-17-2020\", \"08-18-2020\", \"08-19-2020\", \"08-20-2020\",\n",
    "    \"08-21-2020\", \"08-22-2020\", \"08-23-2020\", \"08-24-2020\", \"08-25-2020\",\n",
    "    \"08-26-2020\", \"08-27-2020\", \"08-28-2020\", \"08-29-2020\", \"08-30-2020\",\n",
    "    \"08-31-2020\"\n",
    "]\n",
    "\n",
    "# specify the base URL\n",
    "base_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "\n",
    "# download CSV files\n",
    "for date in tqdm(dates, desc=\"Downloading files\", unit=\"file\"):\n",
    "    file_url = f\"{base_url}{date}.csv\"\n",
    "    response = requests.get(file_url)\n",
    "    \n",
    "    # check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        with open(f\"{date}.csv\", 'wb') as file:\n",
    "            file.write(response.content)\n",
    "    else:\n",
    "        print(f\"Failed to download {date}.csv\")\n",
    "\n",
    "print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e8e5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and merging: 100%|██████████| 31/31 [00:00<00:00, 76.00file/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "      <th>Incidence_Rate</th>\n",
       "      <th>Case-Fatality_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001.0</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>34.223334</td>\n",
       "      <td>-82.461707</td>\n",
       "      <td>288</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>Abbeville, South Carolina, US</td>\n",
       "      <td>1174.216170</td>\n",
       "      <td>2.430556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001.0</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>30.295065</td>\n",
       "      <td>-92.414197</td>\n",
       "      <td>2331</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2260</td>\n",
       "      <td>Acadia, Louisiana, US</td>\n",
       "      <td>3756.950600</td>\n",
       "      <td>3.045903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51001.0</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>37.767072</td>\n",
       "      <td>-75.632346</td>\n",
       "      <td>1077</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1062</td>\n",
       "      <td>Accomack, Virginia, US</td>\n",
       "      <td>3332.714445</td>\n",
       "      <td>1.392758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16001.0</td>\n",
       "      <td>Ada</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>43.452658</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>8004</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>7942</td>\n",
       "      <td>Ada, Idaho, US</td>\n",
       "      <td>1662.004996</td>\n",
       "      <td>0.774613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19001.0</td>\n",
       "      <td>Adair</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>41.330756</td>\n",
       "      <td>-94.471059</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Adair, Iowa, US</td>\n",
       "      <td>279.642058</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS     Admin2  Province_State Country_Region          Last_Update  \\\n",
       "0  45001.0  Abbeville  South Carolina             US  2020-08-02 04:34:47   \n",
       "1  22001.0     Acadia       Louisiana             US  2020-08-02 04:34:47   \n",
       "2  51001.0   Accomack        Virginia             US  2020-08-02 04:34:47   \n",
       "3  16001.0        Ada           Idaho             US  2020-08-02 04:34:47   \n",
       "4  19001.0      Adair            Iowa             US  2020-08-02 04:34:47   \n",
       "\n",
       "         Lat       Long_  Confirmed  Deaths  Recovered  Active  \\\n",
       "0  34.223334  -82.461707        288       7          0     281   \n",
       "1  30.295065  -92.414197       2331      71          0    2260   \n",
       "2  37.767072  -75.632346       1077      15          0    1062   \n",
       "3  43.452658 -116.241552       8004      62          0    7942   \n",
       "4  41.330756  -94.471059         20       0          0      20   \n",
       "\n",
       "                    Combined_Key  Incidence_Rate  Case-Fatality_Ratio  \n",
       "0  Abbeville, South Carolina, US     1174.216170             2.430556  \n",
       "1          Acadia, Louisiana, US     3756.950600             3.045903  \n",
       "2         Accomack, Virginia, US     3332.714445             1.392758  \n",
       "3                 Ada, Idaho, US     1662.004996             0.774613  \n",
       "4                Adair, Iowa, US      279.642058             0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# declare result to be a pandas datframe\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for date in tqdm(dates, desc=\"Loading and merging\", unit=\"file\"):\n",
    "    file_path = f\"{date}.csv\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        result = pd.concat([result, data], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found. Skipping.\")\n",
    "\n",
    "# check what the merged data looks like in the pd dataframe\n",
    "result.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4274b",
   "metadata": {},
   "source": [
    "**2. Drop the Case-Fatality_Ration column from the dataset**\n",
    "\n",
    "Note: we remove this column to calculate it based on two other features in the next step. This action is solely undertaken for the purpose of practicing feature engineering in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163cfba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "      <th>Incidence_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001.0</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>34.223334</td>\n",
       "      <td>-82.461707</td>\n",
       "      <td>288</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>Abbeville, South Carolina, US</td>\n",
       "      <td>1174.216170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001.0</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>30.295065</td>\n",
       "      <td>-92.414197</td>\n",
       "      <td>2331</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2260</td>\n",
       "      <td>Acadia, Louisiana, US</td>\n",
       "      <td>3756.950600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51001.0</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>37.767072</td>\n",
       "      <td>-75.632346</td>\n",
       "      <td>1077</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1062</td>\n",
       "      <td>Accomack, Virginia, US</td>\n",
       "      <td>3332.714445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16001.0</td>\n",
       "      <td>Ada</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>43.452658</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>8004</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>7942</td>\n",
       "      <td>Ada, Idaho, US</td>\n",
       "      <td>1662.004996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19001.0</td>\n",
       "      <td>Adair</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>41.330756</td>\n",
       "      <td>-94.471059</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Adair, Iowa, US</td>\n",
       "      <td>279.642058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS     Admin2  Province_State Country_Region          Last_Update  \\\n",
       "0  45001.0  Abbeville  South Carolina             US  2020-08-02 04:34:47   \n",
       "1  22001.0     Acadia       Louisiana             US  2020-08-02 04:34:47   \n",
       "2  51001.0   Accomack        Virginia             US  2020-08-02 04:34:47   \n",
       "3  16001.0        Ada           Idaho             US  2020-08-02 04:34:47   \n",
       "4  19001.0      Adair            Iowa             US  2020-08-02 04:34:47   \n",
       "\n",
       "         Lat       Long_  Confirmed  Deaths  Recovered  Active  \\\n",
       "0  34.223334  -82.461707        288       7          0     281   \n",
       "1  30.295065  -92.414197       2331      71          0    2260   \n",
       "2  37.767072  -75.632346       1077      15          0    1062   \n",
       "3  43.452658 -116.241552       8004      62          0    7942   \n",
       "4  41.330756  -94.471059         20       0          0      20   \n",
       "\n",
       "                    Combined_Key  Incidence_Rate  \n",
       "0  Abbeville, South Carolina, US     1174.216170  \n",
       "1          Acadia, Louisiana, US     3756.950600  \n",
       "2         Accomack, Virginia, US     3332.714445  \n",
       "3                 Ada, Idaho, US     1662.004996  \n",
       "4                Adair, Iowa, US      279.642058  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the Case-Fatality_Ration column from the dataset\n",
    "\n",
    "result = result.drop(columns=['Case-Fatality_Ratio'])\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc37b2f",
   "metadata": {},
   "source": [
    "**3. Feature Engineering:**\n",
    "\n",
    "Create a new feature 'CFR' (Case Fatality Rate) using the formula: (Deaths / Confirmed) * 100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84367d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "      <th>Incidence_Rate</th>\n",
       "      <th>CFR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001.0</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>34.223334</td>\n",
       "      <td>-82.461707</td>\n",
       "      <td>288</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>Abbeville, South Carolina, US</td>\n",
       "      <td>1174.216170</td>\n",
       "      <td>2.430556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001.0</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>30.295065</td>\n",
       "      <td>-92.414197</td>\n",
       "      <td>2331</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2260</td>\n",
       "      <td>Acadia, Louisiana, US</td>\n",
       "      <td>3756.950600</td>\n",
       "      <td>3.045903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51001.0</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>37.767072</td>\n",
       "      <td>-75.632346</td>\n",
       "      <td>1077</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1062</td>\n",
       "      <td>Accomack, Virginia, US</td>\n",
       "      <td>3332.714445</td>\n",
       "      <td>1.392758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16001.0</td>\n",
       "      <td>Ada</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>43.452658</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>8004</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>7942</td>\n",
       "      <td>Ada, Idaho, US</td>\n",
       "      <td>1662.004996</td>\n",
       "      <td>0.774613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19001.0</td>\n",
       "      <td>Adair</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>41.330756</td>\n",
       "      <td>-94.471059</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Adair, Iowa, US</td>\n",
       "      <td>279.642058</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS     Admin2  Province_State Country_Region          Last_Update  \\\n",
       "0  45001.0  Abbeville  South Carolina             US  2020-08-02 04:34:47   \n",
       "1  22001.0     Acadia       Louisiana             US  2020-08-02 04:34:47   \n",
       "2  51001.0   Accomack        Virginia             US  2020-08-02 04:34:47   \n",
       "3  16001.0        Ada           Idaho             US  2020-08-02 04:34:47   \n",
       "4  19001.0      Adair            Iowa             US  2020-08-02 04:34:47   \n",
       "\n",
       "         Lat       Long_  Confirmed  Deaths  Recovered  Active  \\\n",
       "0  34.223334  -82.461707        288       7          0     281   \n",
       "1  30.295065  -92.414197       2331      71          0    2260   \n",
       "2  37.767072  -75.632346       1077      15          0    1062   \n",
       "3  43.452658 -116.241552       8004      62          0    7942   \n",
       "4  41.330756  -94.471059         20       0          0      20   \n",
       "\n",
       "                    Combined_Key  Incidence_Rate       CFR  \n",
       "0  Abbeville, South Carolina, US     1174.216170  2.430556  \n",
       "1          Acadia, Louisiana, US     3756.950600  3.045903  \n",
       "2         Accomack, Virginia, US     3332.714445  1.392758  \n",
       "3                 Ada, Idaho, US     1662.004996  0.774613  \n",
       "4                Adair, Iowa, US      279.642058  0.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering\n",
    "\n",
    "result['CFR'] = (result['Deaths'] / result['Confirmed']) * 100\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18948058",
   "metadata": {},
   "source": [
    "#### **4.\tData Exploration:**\n",
    "\n",
    "Display basic statistics and information about the dataset.\n",
    "\n",
    "Display summary statistics for the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d272c9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data information: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123418 entries, 0 to 123417\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   FIPS            100809 non-null  float64\n",
      " 1   Admin2          100964 non-null  object \n",
      " 2   Province_State  117962 non-null  object \n",
      " 3   Country_Region  123418 non-null  object \n",
      " 4   Last_Update     123418 non-null  object \n",
      " 5   Lat             120855 non-null  float64\n",
      " 6   Long_           120855 non-null  float64\n",
      " 7   Confirmed       123418 non-null  int64  \n",
      " 8   Deaths          123418 non-null  int64  \n",
      " 9   Recovered       123418 non-null  int64  \n",
      " 10  Active          123418 non-null  int64  \n",
      " 11  Combined_Key    123418 non-null  object \n",
      " 12  Incidence_Rate  120855 non-null  float64\n",
      " 13  CFR             121515 non-null  float64\n",
      "dtypes: float64(5), int64(4), object(5)\n",
      "memory usage: 13.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# display basic statistics and info about the data\n",
    "\n",
    "print(\"Data information: \")\n",
    "print(result.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "502fffdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Numerical Columns:\n",
      "                FIPS            Lat          Long_      Confirmed  \\\n",
      "count  100809.000000  120855.000000  120855.000000  123418.000000   \n",
      "mean    32370.754744      35.738223     -71.401679    5450.939960   \n",
      "std     17976.483772      13.341651      54.822590   28376.383585   \n",
      "min        66.000000     -71.949900    -175.198200       0.000000   \n",
      "25%     19049.000000      33.188201     -96.577496      80.000000   \n",
      "50%     30063.000000      37.877361     -86.803732     323.000000   \n",
      "75%     47039.000000      42.132991     -77.443993    1491.000000   \n",
      "max     99999.000000      71.706900     178.065000  804342.000000   \n",
      "\n",
      "              Deaths     Recovered         Active  Incidence_Rate  \\\n",
      "count  123418.000000  1.234180e+05  123418.000000   120855.000000   \n",
      "mean      207.275722  3.431031e+03    2364.668428     1071.370957   \n",
      "std      1466.677148  3.622184e+04   11012.319484     1120.388169   \n",
      "min         0.000000  0.000000e+00       0.000000        0.000000   \n",
      "25%         1.000000  0.000000e+00      65.000000      345.330366   \n",
      "50%         5.000000  0.000000e+00     269.000000      723.061548   \n",
      "75%        34.000000  0.000000e+00    1048.000000     1434.989384   \n",
      "max     50127.000000  2.184825e+06  273364.000000    14338.886920   \n",
      "\n",
      "                CFR  \n",
      "count  1.215150e+05  \n",
      "mean            inf  \n",
      "std             NaN  \n",
      "min    0.000000e+00  \n",
      "25%    3.802281e-01  \n",
      "50%    1.506429e+00  \n",
      "75%    3.174603e+00  \n",
      "max             inf  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rikuv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1010: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    }
   ],
   "source": [
    "# display summery statistics for numerical columns\n",
    "\n",
    "print(\"Summary Statistics for Numerical Columns:\")\n",
    "print(result.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b123ee",
   "metadata": {},
   "source": [
    "**5.\tDefine Target Variable:**\n",
    "\n",
    "Define a binary target variable (e.g., \"High CFR\" or \"Low CFR\") based on a threshold (min value of the column) of CFR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb2acde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CFR_Label\n",
       "High CFR    93887\n",
       "Low CFR     29531\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define target variable and threshold\n",
    "\n",
    "# set the threshold as the minimum value of the 'CFR' column\n",
    "threshold_cfr = result['CFR'].min()\n",
    "\n",
    "# create a new column 'CFR_Label' with binary labels\n",
    "result['CFR_Label'] = result['CFR'].apply(lambda x: 'High CFR' if x > threshold_cfr else 'Low CFR')\n",
    "\n",
    "result['CFR_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f714c",
   "metadata": {},
   "source": [
    "**6.\tSplit Data:**\n",
    "\n",
    "Split the data into training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5265411c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape - X: (98734, 2) y: (98734,)\n",
      "Test set shape - X: (24684, 2) y: (24684,)\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify the features (X) and the target variable (y)\n",
    "X = result[['Confirmed', 'Deaths']]\n",
    "y = result['CFR_Label']\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape - X:\", X_train.shape, \"y:\", y_train.shape)\n",
    "print(\"Test set shape - X:\", X_test.shape, \"y:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d2832",
   "metadata": {},
   "source": [
    "**7.\tHandle Missing Data:**\n",
    "\n",
    "Implement strategies to handle any remaining missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34d661bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the missing values and drop rows if any\n",
    "\n",
    "if X_train.isnull().sum().any():\n",
    "    X_train = X_train.dropna()\n",
    "\n",
    "if X_test.isnull().sum().any():\n",
    "    X_test = X_test.dropna()\n",
    "\n",
    "if y_train.isnull().sum().any():\n",
    "    y_train = y_train.dropna()\n",
    "\n",
    "if y_test.isnull().sum().any():\n",
    "    y_test = y_test.dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f11118",
   "metadata": {},
   "source": [
    "**8.\tConvert Categorical Variables (if applicable):**\n",
    "\n",
    "If there are categorical variables (e.g., country), encode them using techniques like one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fff789a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "      <th>Incidence_Rate</th>\n",
       "      <th>CFR</th>\n",
       "      <th>CFR_Label_Low CFR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001.0</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>34.223334</td>\n",
       "      <td>-82.461707</td>\n",
       "      <td>288</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>Abbeville, South Carolina, US</td>\n",
       "      <td>1174.216170</td>\n",
       "      <td>2.430556</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001.0</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>30.295065</td>\n",
       "      <td>-92.414197</td>\n",
       "      <td>2331</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2260</td>\n",
       "      <td>Acadia, Louisiana, US</td>\n",
       "      <td>3756.950600</td>\n",
       "      <td>3.045903</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51001.0</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>37.767072</td>\n",
       "      <td>-75.632346</td>\n",
       "      <td>1077</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1062</td>\n",
       "      <td>Accomack, Virginia, US</td>\n",
       "      <td>3332.714445</td>\n",
       "      <td>1.392758</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16001.0</td>\n",
       "      <td>Ada</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>43.452658</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>8004</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>7942</td>\n",
       "      <td>Ada, Idaho, US</td>\n",
       "      <td>1662.004996</td>\n",
       "      <td>0.774613</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19001.0</td>\n",
       "      <td>Adair</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-08-02 04:34:47</td>\n",
       "      <td>41.330756</td>\n",
       "      <td>-94.471059</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Adair, Iowa, US</td>\n",
       "      <td>279.642058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS     Admin2  Province_State Country_Region          Last_Update  \\\n",
       "0  45001.0  Abbeville  South Carolina             US  2020-08-02 04:34:47   \n",
       "1  22001.0     Acadia       Louisiana             US  2020-08-02 04:34:47   \n",
       "2  51001.0   Accomack        Virginia             US  2020-08-02 04:34:47   \n",
       "3  16001.0        Ada           Idaho             US  2020-08-02 04:34:47   \n",
       "4  19001.0      Adair            Iowa             US  2020-08-02 04:34:47   \n",
       "\n",
       "         Lat       Long_  Confirmed  Deaths  Recovered  Active  \\\n",
       "0  34.223334  -82.461707        288       7          0     281   \n",
       "1  30.295065  -92.414197       2331      71          0    2260   \n",
       "2  37.767072  -75.632346       1077      15          0    1062   \n",
       "3  43.452658 -116.241552       8004      62          0    7942   \n",
       "4  41.330756  -94.471059         20       0          0      20   \n",
       "\n",
       "                    Combined_Key  Incidence_Rate       CFR  CFR_Label_Low CFR  \n",
       "0  Abbeville, South Carolina, US     1174.216170  2.430556              False  \n",
       "1          Acadia, Louisiana, US     3756.950600  3.045903              False  \n",
       "2         Accomack, Virginia, US     3332.714445  1.392758              False  \n",
       "3                 Ada, Idaho, US     1662.004996  0.774613              False  \n",
       "4                Adair, Iowa, US      279.642058  0.000000               True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert categorical variable 'CFR_Label' using one-hot encoding\n",
    "result_encoded = pd.get_dummies(result, columns=['CFR_Label'], drop_first=True)\n",
    "\n",
    "result_encoded.head()\n",
    "\n",
    "# we are not converting other variables as they are not needed for our classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8176cee",
   "metadata": {},
   "source": [
    "**9. Train a Classification Model:**\n",
    "\n",
    "Choose a classification algorithm (e.g., Logistic Regression, Decision Tree, Random Forest).\n",
    "\n",
    "Train the model to predict the \"High CFR\" or \"Low CFR\" label based on the selected features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d80f6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a classification model (logistic regression in our case)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "X = result[['Confirmed', 'Deaths']]\n",
    "y = result_encoded['CFR_Label_Low CFR']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# initialize the Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1144bcdc",
   "metadata": {},
   "source": [
    "**10. Model Evaluation:**\n",
    "\n",
    "Evaluate the model's performance using appropriate metrics (e.g., accuracy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "990532d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "\n",
      "Confusion Matrix:\n",
      " [[18756     0]\n",
      " [    0  5928]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00     18756\n",
      "        True       1.00      1.00      1.00      5928\n",
      "\n",
      "    accuracy                           1.00     24684\n",
      "   macro avg       1.00      1.00      1.00     24684\n",
      "weighted avg       1.00      1.00      1.00     24684\n",
      "\n",
      "\n",
      "Precision: 1.0\n",
      "\n",
      "Recall: 1.0\n",
      "\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# display the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "print(\"\\nPrecision:\", precision)\n",
    "print(\"\\nRecall:\", recall)\n",
    "print(\"\\nF1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122aaecc",
   "metadata": {},
   "source": [
    "**11.\tDocumentation:**\n",
    "\n",
    "Provide a report summarizing the findings, including insights from the exploratory analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e97a10",
   "metadata": {},
   "source": [
    "You can write your short report here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was split in 80:20 for training and tests, at 98734 and 24684 samples respectively. \n",
    "The performance of the model reaches 1, or fully precise.\n",
    "\n",
    "The logistic regression model achieved perfect accuracy on the test set.\n",
    "Precision, recall, and F1-score were all 1.0 for both classes, indicating a high level of predictive performance.\n",
    "\n",
    "The perfect accuracy of the model could be due to overfitting of the values or having data leakage. And should be tested on another independent dataset to verify for errors.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028e3d96",
   "metadata": {},
   "source": [
    "## Part B. Machine Learning Project (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18962f77",
   "metadata": {},
   "source": [
    "In this part, you need to use the same data that you have used in the first part (Part A) of this project. \n",
    "\n",
    "The aim of this part is to build a simple regression model on the COVID-19 data that has been loaded through the first step of Part A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da73bd84",
   "metadata": {},
   "source": [
    "**1.Define Target Variable:**\n",
    "\n",
    "Define the target variable (e.g., Deaths) for the regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c82a2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target variables\n",
    "\n",
    "X = result[['Confirmed', 'Recovered']] \n",
    "y = result['Deaths']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fddba65",
   "metadata": {},
   "source": [
    "**2. Split Data:**\n",
    "\n",
    "Split the data into training and testing sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bece4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape - X: (98734, 2) y: (98734,)\n",
      "Test set shape - X: (24684, 2) y: (24684,)\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape - X:\", X_train.shape, \"y:\", y_train.shape)\n",
    "print(\"Test set shape - X:\", X_test.shape, \"y:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12a20f",
   "metadata": {},
   "source": [
    "**3.\tHandle Missing Data:**\n",
    "\n",
    "Implement strategies to handle any remaining missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd82db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing data\n",
    "\n",
    "# check for missing values in the training set\n",
    "if X_train.isnull().any().any():\n",
    "    # fill missing values with the mean\n",
    "    X_train = X_train.fillna(X_train.mean())\n",
    "\n",
    "# check for missing values in the test set\n",
    "if X_test.isnull().any().any():\n",
    "    # fill missing values with the mean\n",
    "    X_test = X_test.fillna(X_test.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f5f280",
   "metadata": {},
   "source": [
    "**4.\tConvert Categorical Variables (if applicable):**\n",
    "\n",
    "If there are categorical variables (e.g., country), encode them using techniques like one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16176758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical variables\n",
    "\n",
    "# no need for that here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ece0bf",
   "metadata": {},
   "source": [
    "**5. Train a regression Model:**\n",
    "\n",
    "Choose a regression algorithm (e.g., Linear Regression, Random Forest Regression)..\n",
    "\n",
    "Train the model to predict the total deaths based on the selected features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be48a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a regression model (linear regression in our case)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error\n",
    "\n",
    "# initialize the Linear Regression model\n",
    "regression_model = LinearRegression()\n",
    "\n",
    "\n",
    "# train the model on the training set\n",
    "regression_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the target variable for the test set\n",
    "y_pred = regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093e097",
   "metadata": {},
   "source": [
    "**6. Model Evaluation:**\n",
    "\n",
    "Evaluate the model's performance using appropriate regression metrics (e.g., Mean Absolute Error, R-squared).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "352d115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1115243.347313111\n",
      "R-squared: 0.5216224793116986\n",
      "Mean Absolute Error: 150.53034717574616\n",
      "Median Absolute Error: 8.12417870408489\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mde = median_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Median Absolute Error:\", mde)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40351e0",
   "metadata": {},
   "source": [
    "**7. Documentation:**\n",
    "\n",
    "Provide a report summarizing the findings, including insights from the exploratory analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72641615",
   "metadata": {},
   "source": [
    "You can write your short report here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE is relatively high, indicating that there might be a considerable amount of variability that the model is not capturing well.\n",
    "The R² value of 0.5216, or 52%, suggests that the model explains a moderate proportion of the variance, but there is still room for improvement.\n",
    "Mean absolute gives how far off the model is from actuality giving 150 units and being quite significant.\n",
    "The median is smaller, less sensitive measure to extreme values.\n",
    "\n",
    "Compared to the linear model, which had a near perfect fit, the regression model does not. \n",
    "\n",
    "Other algorithms could be used to test their performance against Linear Regressaion and ivnvestigating the outliers and anomalies in the data which are causing the significant variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a8c56",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
